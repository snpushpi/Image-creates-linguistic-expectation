{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e325140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = [[{'An old man sitting on a bench in a public park.': '000000264535.jpg',\n",
    "  'Two ceramic cups, one with a bird and the other with a fox.': '000000305343.jpg',\n",
    "  'Two men are posing for a photo, one man is holding a slice of pizza on a plate, and they are surrounded by other people sitting at tables.': '000000382125.jpg',\n",
    "  'A toddler is sitting on a blanket outdoors eating an apple.': '000000188592.jpg',\n",
    "  'A young woman sitting on a curb next to a fire hydrant writing on a notepad.': '000000547336.jpg',\n",
    "  'Two giraffes standing on a dirt expanse with trees in background.': '000000393282.jpg',\n",
    "  'A teddy bear is sitting on the rail of a wire fence.': '000000549136.jpg',\n",
    "  'A tennis player makes a quick shuffle to return the ball.': '000000325347.jpg',\n",
    "  'Plates of food and two glasses of red wine are on a table.': '000000099039.jpg',\n",
    "  'An empty clean kitchen with cabinetry, stove and dishwasher.': '000000127182.jpg',\n",
    "  'A man holding a baby while standing in front of a mirror.': '000000546475.jpg',\n",
    "  'A cat sitting on the hood of a parked black car in a garage.': '000000010363.jpg',\n",
    "  'A batter swinging a bat at a baseball with the catcher and umpire behind him.': '0',\n",
    "  'A refrigerator mostly empty with only a few bottles of water inside.': '1',\n",
    "  'A heavily lit-up building in front of a river.': '2',\n",
    "  'A city skyline is shown with a subway train coming around the bend.': '3',\n",
    "  'A stop sign located at the intersection of East Village and Woodfield Rd.': '4',\n",
    "  'A tray topped with a chicken sandwich next to a cup of fries.': '5',\n",
    "  'A baby elephant walking through a shallow pool of flowing water.': '6',\n",
    "  'Several containers of food and beverages on a wooden table outdoors.': '7',\n",
    "  'Some control buttons on an orange and silver electronic device.': '8',\n",
    "  'A bird sits atop a wooden post and watches its surroundings.': '9',\n",
    "  'A person holding an object in front of a panda bear.': '10',\n",
    "  'People are on the beach flying kites that look like arches in the sky.': '11',\n",
    "  'A huge dragon kite flown with a steeple in the background.': 'w/000000562818.jpg',\n",
    "  'The bench is in a shady area surrounded by plants.': 'w/000000518213.jpg',\n",
    "  'A dried black flower in a long, tall black and white vase.': 'w/000000001353.jpg',\n",
    "  'A man walking with an umbrella near a railing above a river.': 'w/000000415536.jpg',\n",
    "  'A giraffe standing in front of a grassy plain and blue sky.': 'w/000000397279.jpg',\n",
    "  'People watch from a large boat as a smaller boat is lowered into the ocean.': 'w/000000013597.jpg',\n",
    "  'A girl in an orange sweater is sitting on a skateboard.': 'w/000000097679.jpg',\n",
    "  'A woman in a white shirt standing in front of a fence smiling.': 'w/000000260106.jpg',\n",
    "  'A group of elephants being cleaned by their handlers in a river.': 'w/000000544565.jpg',\n",
    "  'An outdoor market has a wide variety of fruit to choose from.': 'w/000000328117.jpg',\n",
    "  'A woman and man sit under a large blue umbrella on a grassy lot.': 'w/000000544811.jpg',\n",
    "  'A vandalized stop sign in the dark with a sky background.': 'w/000000329827.jpg'},\n",
    " {'An old man sitting on a bench in a public park.': '0',\n",
    "  'Two ceramic cups, one with a bird and the other with a fox.': '1',\n",
    "  'Two men are posing for a photo, one man is holding a slice of pizza on a plate, and they are surrounded by other people sitting at tables.': '2',\n",
    "  'A toddler is sitting on a blanket outdoors eating an apple.': '3',\n",
    "  'A young woman sitting on a curb next to a fire hydrant writing on a notepad.': '4',\n",
    "  'Two giraffes standing on a dirt expanse with trees in background.': '5',\n",
    "  'A teddy bear is sitting on the rail of a wire fence.': '6',\n",
    "  'A tennis player makes a quick shuffle to return the ball.': '7',\n",
    "  'Plates of food and two glasses of red wine are on a table.': '8',\n",
    "  'An empty clean kitchen with cabinetry, stove and dishwasher.': '9',\n",
    "  'A man holding a baby while standing in front of a mirror.': '10',\n",
    "  'A cat sitting on the hood of a parked black car in a garage.': '11',\n",
    "  'A batter swinging a bat at a baseball with the catcher and umpire behind him.': 'w/000000308531.jpg',\n",
    "  'A refrigerator mostly empty with only a few bottles of water inside.': 'w/000000017207.jpg',\n",
    "  'A heavily lit-up building in front of a river.': 'w/000000114049.jpg',\n",
    "  'A city skyline is shown with a subway train coming around the bend.': 'w/000000160666.jpg',\n",
    "  'A stop sign located at the intersection of East Village and Woodfield Rd.': 'w/000000389684.jpg',\n",
    "  'A tray topped with a chicken sandwich next to a cup of fries.': 'w/000000578967.jpg',\n",
    "  'A baby elephant walking through a shallow pool of flowing water.': 'w/000000295138.jpg',\n",
    "  'Several containers of food and beverages on a wooden table outdoors.': 'w/000000277020.jpg',\n",
    "  'Some control buttons on an orange and silver electronic device.': 'w/000000570736.jpg',\n",
    "  'A bird sits atop a wooden post and watches its surroundings.': 'w/000000309467.jpg',\n",
    "  'A person holding an object in front of a panda bear.': 'w/000000198510.jpg',\n",
    "  'People are on the beach flying kites that look like arches in the sky.': 'w/000000023937.jpg',\n",
    "  'A huge dragon kite flown with a steeple in the background.': '000000549738.jpg',\n",
    "  'The bench is in a shady area surrounded by plants.': '000000351589.jpg',\n",
    "  'A dried black flower in a long, tall black and white vase.': '000000375078.jpg',\n",
    "  'A man walking with an umbrella near a railing above a river.': '000000288042.jpg',\n",
    "  'A giraffe standing in front of a grassy plain and blue sky.': '000000212895.jpg',\n",
    "  'People watch from a large boat as a smaller boat is lowered into the ocean.': '000000422706.jpg',\n",
    "  'A girl in an orange sweater is sitting on a skateboard.': '000000108495.jpg',\n",
    "  'A woman in a white shirt standing in front of a fence smiling.': '000000477689.jpg',\n",
    "  'A group of elephants being cleaned by their handlers in a river.': '000000465180.jpg',\n",
    "  'An outdoor market has a wide variety of fruit to choose from.': '000000303566.jpg',\n",
    "  'A woman and man sit under a large blue umbrella on a grassy lot.': '000000309964.jpg',\n",
    "  'A vandalized stop sign in the dark with a sky background.': '000000122745.jpg'},\n",
    " {'An old man sitting on a bench in a public park.': 'w/000000127987.jpg',\n",
    "  'Two ceramic cups, one with a bird and the other with a fox.': 'w/000000113051.jpg',\n",
    "  'Two men are posing for a photo, one man is holding a slice of pizza on a plate, and they are surrounded by other people sitting at tables.': 'w/000000068933.jpg',\n",
    "  'A toddler is sitting on a blanket outdoors eating an apple.': 'w/000000263679.jpg',\n",
    "  'A young woman sitting on a curb next to a fire hydrant writing on a notepad.': 'w/000000406129.jpg',\n",
    "  'Two giraffes standing on a dirt expanse with trees in background.': 'w/000000107226.jpg',\n",
    "  'A teddy bear is sitting on the rail of a wire fence.': 'w/000000027620.jpg',\n",
    "  'A tennis player makes a quick shuffle to return the ball.': 'w/000000567825.jpg',\n",
    "  'Plates of food and two glasses of red wine are on a table.': 'w/000000407868.jpg',\n",
    "  'An empty clean kitchen with cabinetry, stove and dishwasher.': 'w/000000085157.jpg',\n",
    "  'A man holding a baby while standing in front of a mirror.': 'w/000000050638.jpg',\n",
    "  'A cat sitting on the hood of a parked black car in a garage.': 'w/000000320425.jpg',\n",
    "  'A batter swinging a bat at a baseball with the catcher and umpire behind him.': '000000084031.jpg',\n",
    "  'A refrigerator mostly empty with only a few bottles of water inside.': '000000132329.jpg',\n",
    "  'A heavily lit-up building in front of a river.': '000000466416.jpg',\n",
    "  'A city skyline is shown with a subway train coming around the bend.': '000000127624.jpg',\n",
    "  'A stop sign located at the intersection of East Village and Woodfield Rd.': '000000579893.jpg',\n",
    "  'A tray topped with a chicken sandwich next to a cup of fries.': '000000218249.jpg',\n",
    "  'A baby elephant walking through a shallow pool of flowing water.': '000000556765.jpg',\n",
    "  'Several containers of food and beverages on a wooden table outdoors.': '000000170670.jpg',\n",
    "  'Some control buttons on an orange and silver electronic device.': '000000022623.jpg',\n",
    "  'A bird sits atop a wooden post and watches its surroundings.': '000000523811.jpg',\n",
    "  'A person holding an object in front of a panda bear.': '000000390826.jpg',\n",
    "  'People are on the beach flying kites that look like arches in the sky.': '000000224664.jpg',\n",
    "  'A huge dragon kite flown with a steeple in the background.': '0',\n",
    "  'The bench is in a shady area surrounded by plants.': '1',\n",
    "  'A dried black flower in a long, tall black and white vase.': '2',\n",
    "  'A man walking with an umbrella near a railing above a river.': '3',\n",
    "  'A giraffe standing in front of a grassy plain and blue sky.': '4',\n",
    "  'People watch from a large boat as a smaller boat is lowered into the ocean.': '5',\n",
    "  'A girl in an orange sweater is sitting on a skateboard.': '6',\n",
    "  'A woman in a white shirt standing in front of a fence smiling.': '7',\n",
    "  'A group of elephants being cleaned by their handlers in a river.': '8',\n",
    "  'An outdoor market has a wide variety of fruit to choose from.': '9',\n",
    "  'A woman and man sit under a large blue umbrella on a grassy lot.': '10',\n",
    "  'A vandalized stop sign in the dark with a sky background.': '11'}],\n",
    " [{'A tennis player swinging a racket at a public tennis match.': '000000386352.jpg',\n",
    "  'The antique bed has elaborate wood decoration on the frame.': '000000263644.jpg',\n",
    "  'A plate of cupcakes on a napkin with spoons and drink glasses.': '000000242060.jpg',\n",
    "  'A woman standing next to a young man near a pile of fruit.': '000000280891.jpg',\n",
    "  'French bread on a plate with eggs, bacon and banana slices atop the bread.': '000000468925.jpg',\n",
    "  'A person holding a book with a bird sitting on the book.': '000000542776.jpg',\n",
    "  'A giraffe is peeking around the side of a wall at the camera.': '000000299720.jpg',\n",
    "  'A woman holding an umbrella sitting on a blanket next to two dogs.': '000000182805.jpg',\n",
    "  'A white cake covered in flowers and white frosting.': '000000453040.jpg',\n",
    "  'A man in shorts is taking a picture next to a red light.': '000000017905.jpg',\n",
    "  'A desk with two computer monitors, a laptop computer, keyboard and set of headphones.': '000000555009.jpg',\n",
    "  'An airplane flies high above in the sky with telephone lines in the picture as well.': '000000101787.jpg',\n",
    "  'Multiple aircraft suspended from the ceiling of a museum.': '0',\n",
    "  'A dark colored cat that is looking up at a television that is on and has a program playing on it.': '1',\n",
    "  'A man with glasses sitting in front of a laptop computer.': '2',\n",
    "  'A young man is having some wine and something to eat.': '3',\n",
    "  'A man wears a suit with a blue shirt and a multicolored tie.': '4',\n",
    "  'A clock between two bronze flamingo statues on a black box.': '5',\n",
    "  'Some food is on the counter including a glass of water, rice, vegetables, and more.': '6',\n",
    "  'Three people in work uniforms and visors standing together in front of various types of donuts.': '7',\n",
    "  'A man walking with a drink and a bag while listening to earbud headphones.': '8',\n",
    "  'A parking meter next to a ladder with bowling balls on each rung.': '9',\n",
    "  'A little funny rabbit figure is sitting in the middle of half eaten pizza.': '10',\n",
    "  'A lazy zebra lays in the straw near a rocky field.': '11',\n",
    "  'A person sitting on a park bench is looking at a large field.': 'w/000000386277.jpg',\n",
    "  'A calculator and cell phone lay on a desk in front of a keyboard.': 'w/000000312421.jpg',\n",
    "  'A sign that gives directions to drivers driving down the road.': 'w/000000526728.jpg',\n",
    "  'A child kneeling in front of an open refrigerator and looking in at an empty lower shelf.': 'w/000000536343.jpg',\n",
    "  'A spread of pastries and doughnuts available for purchase.': 'w/000000071938.jpg',\n",
    "  'A puppy has pulled toilet paper across the bathroom floor.': 'w/000000425702.jpg',\n",
    "  'A man sitting on the ground, fixing a motorcycle wheel.': 'w/000000015597.jpg',\n",
    "  'A stop sign installed upside down on a street corner.': 'w/000000242287.jpg',\n",
    "  'Several vehicles and a horse-drawn cart pull up outside of a building.': 'w/000000446207.jpg',\n",
    "  'Three men sitting at a table with some wine glasses.': 'w/000000192607.jpg',\n",
    "  'A city street at dusk with a street light that is on and a stop sign across the street.': 'w/000000187243.jpg',\n",
    "  'A close-up photo of a man as he holds a piece of bread in his mouth.': 'w/000000508917.jpg'},\n",
    " {'A tennis player swinging a racket at a public tennis match.': '0',\n",
    "  'The antique bed has elaborate wood decoration on the frame.': '1',\n",
    "  'A plate of cupcakes on a napkin with spoons and drink glasses.': '2',\n",
    "  'A woman standing next to a young man near a pile of fruit.': '3',\n",
    "  'French bread on a plate with eggs, bacon and banana slices atop the bread.': '4',\n",
    "  'A person holding a book with a bird sitting on the book.': '5',\n",
    "  'A giraffe is peeking around the side of a wall at the camera.': '6',\n",
    "  'A woman holding an umbrella sitting on a blanket next to two dogs.': '7',\n",
    "  'A white cake covered in flowers and white frosting.': '8',\n",
    "  'A man in shorts is taking a picture next to a red light.': '9',\n",
    "  'A desk with two computer monitors, a laptop computer, keyboard and set of headphones.': '10',\n",
    "  'An airplane flies high above in the sky with telephone lines in the picture as well.': '11',\n",
    "  'Multiple aircraft suspended from the ceiling of a museum.': 'w/000000204871.jpg',\n",
    "  'A dark colored cat that is looking up at a television that is on and has a program playing on it.': 'w/000000137106.jpg',\n",
    "  'A man with glasses sitting in front of a laptop computer.': 'w/000000128658.jpg',\n",
    "  'A young man is having some wine and something to eat.': 'w/000000239843.jpg',\n",
    "  'A man wears a suit with a blue shirt and a multicolored tie.': 'w/000000071451.jpg',\n",
    "  'A clock between two bronze flamingo statues on a black box.': 'w/000000351823.jpg',\n",
    "  'Some food is on the counter including a glass of water, rice, vegetables, and more.': 'w/000000227399.jpg',\n",
    "  'Three people in work uniforms and visors standing together in front of various types of donuts.': 'w/000000057238.jpg',\n",
    "  'A man walking with a drink and a bag while listening to earbud headphones.': 'w/000000458755.jpg',\n",
    "  'A parking meter next to a ladder with bowling balls on each rung.': 'w/000000088951.jpg',\n",
    "  'A little funny rabbit figure is sitting in the middle of half eaten pizza.': 'w/000000310622.jpg',\n",
    "  'A lazy zebra lays in the straw near a rocky field.': 'w/000000083172.jpg',\n",
    "  'A person sitting on a park bench is looking at a large field.': '000000542423.jpg',\n",
    "  'A calculator and cell phone lay on a desk in front of a keyboard.': '000000561366.jpg',\n",
    "  'A sign that gives directions to drivers driving down the road.': '000000553339.jpg',\n",
    "  'A child kneeling in front of an open refrigerator and looking in at an empty lower shelf.': '000000231339.jpg',\n",
    "  'A spread of pastries and doughnuts available for purchase.': '000000345469.jpg',\n",
    "  'A puppy has pulled toilet paper across the bathroom floor.': '000000061471.jpg',\n",
    "  'A man sitting on the ground, fixing a motorcycle wheel.': '000000013177.jpg',\n",
    "  'A stop sign installed upside down on a street corner.': '000000000724.jpg',\n",
    "  'Several vehicles and a horse-drawn cart pull up outside of a building.': '000000367680.jpg',\n",
    "  'Three men sitting at a table with some wine glasses.': '000000402720.jpg',\n",
    "  'A city street at dusk with a street light that is on and a stop sign across the street.': '000000273617.jpg',\n",
    "  'A close-up photo of a man as he holds a piece of bread in his mouth.': '000000224337.jpg'},\n",
    " {'A tennis player swinging a racket at a public tennis match.': 'w/000000205282.jpg',\n",
    "  'The antique bed has elaborate wood decoration on the frame.': 'w/000000294855.jpg',\n",
    "  'A plate of cupcakes on a napkin with spoons and drink glasses.': 'w/000000512194.jpg',\n",
    "  'A woman standing next to a young man near a pile of fruit.': 'w/000000253433.jpg',\n",
    "  'French bread on a plate with eggs, bacon and banana slices atop the bread.': 'w/000000060823.jpg',\n",
    "  'A person holding a book with a bird sitting on the book.': 'w/000000253742.jpg',\n",
    "  'A giraffe is peeking around the side of a wall at the camera.': 'w/000000036539.jpg',\n",
    "  'A woman holding an umbrella sitting on a blanket next to two dogs.': 'w/000000329827.jpg',\n",
    "  'A white cake covered in flowers and white frosting.': 'w/000000139260.jpg',\n",
    "  'A man in shorts is taking a picture next to a red light.': 'w/000000159311.jpg',\n",
    "  'A desk with two computer monitors, a laptop computer, keyboard and set of headphones.': 'w/000000067213.jpg',\n",
    "  'An airplane flies high above in the sky with telephone lines in the picture as well.': 'w/000000493772.jpg',\n",
    "  'Multiple aircraft suspended from the ceiling of a museum.': '000000502599.jpg',\n",
    "  'A dark colored cat that is looking up at a television that is on and has a program playing on it.': '000000533536.jpg',\n",
    "  'A man with glasses sitting in front of a laptop computer.': '000000477805.jpg',\n",
    "  'A young man is having some wine and something to eat.': '000000425361.jpg',\n",
    "  'A man wears a suit with a blue shirt and a multicolored tie.': '000000131444.jpg',\n",
    "  'A clock between two bronze flamingo statues on a black box.': '000000459500.jpg',\n",
    "  'Some food is on the counter including a glass of water, rice, vegetables, and more.': '000000025986.jpg',\n",
    "  'Three people in work uniforms and visors standing together in front of various types of donuts.': '000000370677.jpg',\n",
    "  'A man walking with a drink and a bag while listening to earbud headphones.': '000000063047.jpg',\n",
    "  'A parking meter next to a ladder with bowling balls on each rung.': '000000135410.jpg',\n",
    "  'A little funny rabbit figure is sitting in the middle of half eaten pizza.': '000000513283.jpg',\n",
    "  'A lazy zebra lays in the straw near a rocky field.': '000000376278.jpg',\n",
    "  'A person sitting on a park bench is looking at a large field.': '0',\n",
    "  'A calculator and cell phone lay on a desk in front of a keyboard.': '1',\n",
    "  'A sign that gives directions to drivers driving down the road.': '2',\n",
    "  'A child kneeling in front of an open refrigerator and looking in at an empty lower shelf.': '3',\n",
    "  'A spread of pastries and doughnuts available for purchase.': '4',\n",
    "  'A puppy has pulled toilet paper across the bathroom floor.': '5',\n",
    "  'A man sitting on the ground, fixing a motorcycle wheel.': '6',\n",
    "  'A stop sign installed upside down on a street corner.': '7',\n",
    "  'Several vehicles and a horse-drawn cart pull up outside of a building.': '8',\n",
    "  'Three men sitting at a table with some wine glasses.': '9',\n",
    "  'A city street at dusk with a street light that is on and a stop sign across the street.': '10',\n",
    "  'A close-up photo of a man as he holds a piece of bread in his mouth.': '11'}],\n",
    " [{'A cat standing on a toilet seat looking at the person taking the photo.': '000000157807.jpg',\n",
    "  'A man in a field of wild flowers holding an orange bat.': '000000510095.jpg',\n",
    "  'A dark colored cat looking at a laptop screen.': '000000525247.jpg',\n",
    "  'A sign mounted to a pole that reads No Stops.': '000000236845.jpg',\n",
    "  'A blue trash removal truck and two vehicles behind it.': '000000295420.jpg',\n",
    "  'The red boat is anchored on the shore of the lake in front of the houses.': '000000410612.jpg',\n",
    "  'A polar bear pokes his head and one paw out of the water.': '000000085478.jpg',\n",
    "  'A large group of people watch as a skater does his tricks.': '000000026690.jpg',\n",
    "  'A baseball player hitting the ball during a baseball game.': '000000223738.jpg',\n",
    "  'A kitchen with a clear counter top and wooden cabinets, along with a white dish washer under the counter.': '000000369503.jpg',\n",
    "  'Two young women are eating hot dogs while walking down the sidewalk.': '000000513567.jpg',\n",
    "  'Two silver cars parked beside each other in parking spots.': '000000089556.jpg',\n",
    "  'A white swan swimming through a lake next to a boat.': '0',\n",
    "  'A person wearing a helmet and goggles riding a snowboard down the slopes.': '1',\n",
    "  'A bathroom with curtains that have floral decor on them.': '2',\n",
    "  'A patio table with two dinner plates of food and two bowls of salad.': '3',\n",
    "  'A green stop light with a tall building lighted up in the background at night.': '4',\n",
    "  'A fruit smoothie glass on a plate with two strawberries for garnish.': '5',\n",
    "  'A baseball player is waiting for the pitch while standing in the batters box.': '6',\n",
    "  'A cup of coffee with a plate of banana slices on bread.': '7',\n",
    "  'A large crowd of people riding horses walks along a trail.': '8',\n",
    "  'A colorful truck with a full load of sticks and twigs.': '9',\n",
    "  'A car sitting in the middle of the road near a construction vehicle.': '10',\n",
    "  'A black and white picture of people walking in the rain under umbrellas.': '11',\n",
    "  'A light blue bicycle chained to a pole on the sidewalk in front of a red building.': 'w/000000512836.jpg',\n",
    "  'A young boy is standing against a wall eating an apple.': 'w/000000149622.jpg',\n",
    "  'A young girl looking at a huge pizza with surprise.': 'w/000000061418.jpg',\n",
    "  'A white frosted cake sitting in front of some white flowers.': 'w/000000090062.jpg',\n",
    "  'A tray full of breakfast foods and drinks on a bed.': 'w/000000339823.jpg',\n",
    "  'A dog laying on its side with a remote control under its paw.': 'w/000000323355.jpg',\n",
    "  'Two men holding big wooden sticks with a lot of elephants in the background.': 'w/000000450686.jpg',\n",
    "  'A black cat sitting inside of a sink in the bathroom.': 'w/000000308799.jpg',\n",
    "  'A row of surfboards sticking out of the sand sitting next to each other.': 'w/000000397303.jpg',\n",
    "  'A man covering his eyes while standing next to multiple boxes filled with bananas.': 'w/000000521405.jpg',\n",
    "  'There is an indoor toilet underneath a sign that says please flush.': 'w/000000308466.jpg',\n",
    "  'A table topped with a cake covered in berries next to a plate of sandwiches.': 'w/000000259830.jpg'},\n",
    " {'A cat standing on a toilet seat looking at the person taking the photo.': '0',\n",
    "  'A man in a field of wild flowers holding an orange bat.': '1',\n",
    "  'A dark colored cat looking at a laptop screen.': '2',\n",
    "  'A sign mounted to a pole that reads No Stops.': '3',\n",
    "  'A blue trash removal truck and two vehicles behind it.': '4',\n",
    "  'The red boat is anchored on the shore of the lake in front of the houses.': '5',\n",
    "  'A polar bear pokes his head and one paw out of the water.': '6',\n",
    "  'A large group of people watch as a skater does his tricks.': '7',\n",
    "  'A baseball player hitting the ball during a baseball game.': '8',\n",
    "  'A kitchen with a clear counter top and wooden cabinets, along with a white dish washer under the counter.': '9',\n",
    "  'Two young women are eating hot dogs while walking down the sidewalk.': '10',\n",
    "  'Two silver cars parked beside each other in parking spots.': '11',\n",
    "  'A white swan swimming through a lake next to a boat.': 'w/000000273420.jpg',\n",
    "  'A person wearing a helmet and goggles riding a snowboard down the slopes.': 'w/000000327890.jpg',\n",
    "  'A bathroom with curtains that have floral decor on them.': 'w/000000288430.jpg',\n",
    "  'A patio table with two dinner plates of food and two bowls of salad.': 'w/000000508602.jpg',\n",
    "  'A green stop light with a tall building lighted up in the background at night.': 'w/000000320554.jpg',\n",
    "  'A fruit smoothie glass on a plate with two strawberries for garnish.': 'w/000000084241.jpg',\n",
    "  'A baseball player is waiting for the pitch while standing in the batters box.': 'w/000000463918.jpg',\n",
    "  'A cup of coffee with a plate of banana slices on bread.': 'w/000000131379.jpg',\n",
    "  'A large crowd of people riding horses walks along a trail.': 'w/000000248980.jpg',\n",
    "  'A colorful truck with a full load of sticks and twigs.': 'w/000000125062.jpg',\n",
    "  'A car sitting in the middle of the road near a construction vehicle.': 'w/000000410880.jpg',\n",
    "  'A black and white picture of people walking in the rain under umbrellas.': 'w/000000020333.jpg',\n",
    "  'A light blue bicycle chained to a pole on the sidewalk in front of a red building.': '000000426166.jpg',\n",
    "  'A young boy is standing against a wall eating an apple.': '000000349594.jpg',\n",
    "  'A young girl looking at a huge pizza with surprise.': '000000374982.jpg',\n",
    "  'A white frosted cake sitting in front of some white flowers.': '000000556873.jpg',\n",
    "  'A tray full of breakfast foods and drinks on a bed.': '000000192904.jpg',\n",
    "  'A dog laying on its side with a remote control under its paw.': '000000273642.jpg',\n",
    "  'Two men holding big wooden sticks with a lot of elephants in the background.': '000000173799.jpg',\n",
    "  'A black cat sitting inside of a sink in the bathroom.': '000000501523.jpg',\n",
    "  'A row of surfboards sticking out of the sand sitting next to each other.':'000000127517.jpg',\n",
    "  'A man covering his eyes while standing next to multiple boxes filled with bananas.': '000000527029.jpg',\n",
    "  'There is an indoor toilet underneath a sign that says please flush.': '000000394328.jpg',\n",
    "  'A table topped with a cake covered in berries next to a plate of sandwiches.': '000000002157.jpg'},\n",
    " {'A cat standing on a toilet seat looking at the person taking the photo.': 'w/000000079144.jpg',\n",
    "  'A man in a field of wild flowers holding an orange bat.': 'w/000000097924.jpg',\n",
    "  'A dark colored cat looking at a laptop screen.': 'w/000000095899.jpg',\n",
    "  'A sign mounted to a pole that reads No Stops.': 'w/000000159458.jpg',\n",
    "  'A blue trash removal truck and two vehicles behind it.': 'w/000000227686.jpg',\n",
    "  'The red boat is anchored on the shore of the lake in front of the houses.': 'w/000000387916.jpg',\n",
    "  'A polar bear pokes his head and one paw out of the water.': 'w/000000338304.jpg',\n",
    "  'A large group of people watch as a skater does his tricks.': 'w/000000254368.jpg',\n",
    "  'A baseball player hitting the ball during a baseball game.': 'w/000000277005.jpg',\n",
    "  'A kitchen with a clear counter top and wooden cabinets, along with a white dish washer under the counter.': 'w/000000356261.jpg',\n",
    "  'Two young women are eating hot dogs while walking down the sidewalk.': 'w/000000210299.jpg',\n",
    "  'Two silver cars parked beside each other in parking spots.': 'w/000000031620.jpg',\n",
    "  'A white swan swimming through a lake next to a boat.': '000000475904.jpg',\n",
    "  'A person wearing a helmet and goggles riding a snowboard down the slopes.': '000000080273.jpg',\n",
    "  'A bathroom with curtains that have floral decor on them.': '000000446574.jpg',\n",
    "  'A patio table with two dinner plates of food and two bowls of salad.': '000000237517.jpg',\n",
    "  'A green stop light with a tall building lighted up in the background at night.': '000000351559.jpg',\n",
    "  'A fruit smoothie glass on a plate with two strawberries for garnish.': '000000331569.jpg',\n",
    "  'A baseball player is waiting for the pitch while standing in the batters box.': '000000388056.jpg',\n",
    "  'A cup of coffee with a plate of banana slices on bread.': '000000066706.jpg',\n",
    "  'A large crowd of people riding horses walks along a trail.': '000000439180.jpg',\n",
    "  'A colorful truck with a full load of sticks and twigs.': '000000188439.jpg',\n",
    "  'A car sitting in the middle of the road near a construction vehicle.': '000000155341.jpg',\n",
    "  'A black and white picture of people walking in the rain under umbrellas.': '000000278848.jpg',\n",
    "  'A light blue bicycle chained to a pole on the sidewalk in front of a red building.': '0',\n",
    "  'A young boy is standing against a wall eating an apple.': '1',\n",
    "  'A young girl looking at a huge pizza with surprise.': '2',\n",
    "  'A white frosted cake sitting in front of some white flowers.': '3',\n",
    "  'A tray full of breakfast foods and drinks on a bed.': '4',\n",
    "  'A dog laying on its side with a remote control under its paw.': '5',\n",
    "  'Two men holding big wooden sticks with a lot of elephants in the background.': '6',\n",
    "  'A black cat sitting inside of a sink in the bathroom.': '7',\n",
    "  'A row of surfboards sticking out of the sand sitting next to each other.': '8',\n",
    "  'A man covering his eyes while standing next to multiple boxes filled with bananas.': '9',\n",
    "  'There is an indoor toilet underneath a sign that says please flush.': '10',\n",
    "  'A table topped with a cake covered in berries next to a plate of sandwiches.': '11'}]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d771bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete rows where Type=practice\n",
    "import pandas as pd\n",
    "df = pd.read_csv('final_results_prelim_v2.csv')\n",
    "df = df[df['Type'] != 'practice']\n",
    "\n",
    "# Reset the index of the dataframe if needed\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa256947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df['Sentence'].str.replace('%2C', ',')\n",
    "df['Word'] = df['Word'].str.replace('%2C', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc28413",
   "metadata": {},
   "source": [
    "# Adding Condition ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69060dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Condition_ID\n",
    "def compute_condition_id(row):\n",
    "    first_ind = int(row['Type'][-2])\n",
    "    second_ind = int(row['Type'][-1])\n",
    "    dictionary = all_items[first_ind][second_ind]\n",
    "    if dictionary[row['Sentence']].startswith('w'):\n",
    "        return 'wrong'\n",
    "    elif dictionary[row['Sentence']].isdigit():\n",
    "        return 'no'\n",
    "    else:\n",
    "        return 'correct'\n",
    "\n",
    "\n",
    "# Use the apply function to create column D\n",
    "df['Condition_ID'] = df.apply(compute_condition_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc9c305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Controller</th>\n",
       "      <th>Item</th>\n",
       "      <th>Element</th>\n",
       "      <th>Type</th>\n",
       "      <th>Group</th>\n",
       "      <th>Wordnum</th>\n",
       "      <th>Word</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Word On</th>\n",
       "      <th>Correct</th>\n",
       "      <th>First_RT</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>RT</th>\n",
       "      <th>Condition_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>x-x-x</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>599</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>599</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>young</td>\n",
       "      <td>bills</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>636</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>636</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>woman</td>\n",
       "      <td>goals</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>552</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>552</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>sitting</td>\n",
       "      <td>revenue</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>1090</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>1090</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>jack</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>663</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>663</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33956</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>banana</td>\n",
       "      <td>portal</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>673</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>673</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33957</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>slices</td>\n",
       "      <td>devout</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>997</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>997</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33958</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>atop</td>\n",
       "      <td>sane</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1080</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>1080</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33959</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>the</td>\n",
       "      <td>knew</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>494</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>494</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33960</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>bread.</td>\n",
       "      <td>fails.</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1048</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>1048</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33961 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time_ID                        Subject_ID Controller  Item  Element  \\\n",
       "0      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "1      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "2      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "3      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "4      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "...           ...                               ...        ...   ...      ...   \n",
       "33956  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33957  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33958  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33959  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33960  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "\n",
       "           Type  Group  Wordnum     Word      Alt  Word On Correct First_RT  \\\n",
       "0      group_01      4        0        A    x-x-x        0     yes      599   \n",
       "1      group_01      4        1    young    bills        1     yes      636   \n",
       "2      group_01      4        2    woman    goals        1     yes      552   \n",
       "3      group_01      4        3  sitting  revenue        1     yes     1090   \n",
       "4      group_01      4        4       on     jack        0     yes      663   \n",
       "...         ...    ...      ...      ...      ...      ...     ...      ...   \n",
       "33956  group_11      4        9   banana   portal        1     yes      673   \n",
       "33957  group_11      4       10   slices   devout        0     yes      997   \n",
       "33958  group_11      4       11     atop     sane        0     yes     1080   \n",
       "33959  group_11      4       12      the     knew        0     yes      494   \n",
       "33960  group_11      4       13   bread.   fails.        0     yes     1048   \n",
       "\n",
       "                                                Sentence    RT Condition_ID  \n",
       "0      A young woman sitting on a curb next to a fire...   599           no  \n",
       "1      A young woman sitting on a curb next to a fire...   636           no  \n",
       "2      A young woman sitting on a curb next to a fire...   552           no  \n",
       "3      A young woman sitting on a curb next to a fire...  1090           no  \n",
       "4      A young woman sitting on a curb next to a fire...   663           no  \n",
       "...                                                  ...   ...          ...  \n",
       "33956  French bread on a plate with eggs, bacon and b...   673           no  \n",
       "33957  French bread on a plate with eggs, bacon and b...   997           no  \n",
       "33958  French bread on a plate with eggs, bacon and b...  1080           no  \n",
       "33959  French bread on a plate with eggs, bacon and b...   494           no  \n",
       "33960  French bread on a plate with eggs, bacon and b...  1048           no  \n",
       "\n",
       "[33961 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf9b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('final_results_prelim_v21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52959da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop([\"Time_ID\", \"Controller\",\"Item\",\"Element\",\"Alt\",\"Word On\",\"Correct\",\"First_RT\",\"Type\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11328e",
   "metadata": {},
   "source": [
    "# Adding Correctness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d640b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correctness']=['correct']*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d53a924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['First_RT']==\"None\") & (df['RT']==\"None\"),'correctness']='unavailable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f9650bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['First_RT']!=\"None\") & (df['RT']==\"None\"),'correctness']='wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400499e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2044f8f8",
   "metadata": {},
   "source": [
    "# dropping the first word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65dd243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows of the first word\n",
    "df = df[df['Wordnum']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce7cc94",
   "metadata": {},
   "source": [
    "# Adding GPT2 surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5e509e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Add surprisals\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02b7dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['gpt2_surp']=[None]*len(df)\n",
    "subject_ids = df['Subject_ID'].unique()\n",
    "sentences = df['Sentence'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f86eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "def calculate_surprisal(sentence):\n",
    "    result = [0]\n",
    "    encoded = tokenizer.encode(sentence, return_tensors= 'pt')\n",
    "    output_logits = model(encoded).logits.detach()\n",
    "    #token_probs = output_logits\n",
    "    for i in range(0, encoded.shape[1]-1):\n",
    "        token_logits = output_logits[:,i,:]\n",
    "        token_prob = torch.log_softmax(token_logits,dim=-1)[0,encoded[0,i+1]]\n",
    "        token_surprisal = -token_prob/math.log(2)\n",
    "        result.append(token_surprisal.item())\n",
    "        # print(tokenizer.convert_ids_to_tokens([encoded[0,i+1]]), token_surprisal)\n",
    "    return result, tokenizer.tokenize(sentence)\n",
    "\n",
    "def post_processing(tokenized_sent, surps, sentence):\n",
    "    final_surp = []\n",
    "    counter = 0\n",
    "    assert len(tokenized_sent)==len(surps)\n",
    "    for (i,token) in enumerate(tokenized_sent):\n",
    "        if not token.startswith('Ġ'):\n",
    "            counter+=surps[i]\n",
    "            if i==len(tokenized_sent)-1:\n",
    "                final_surp.append(counter)\n",
    "        else:\n",
    "            final_surp.append(counter)\n",
    "            counter = surps[i]\n",
    "#     if len(final_surp)!= len(sentence.split(' ')):\n",
    "#         print(tokenized_sent,sentence,len(final_surp),sentence.split(' '))\n",
    "    assert len(final_surp)== len(sentence.split(' '))\n",
    "    return final_surp[1:]\n",
    "    \n",
    "def run():\n",
    "    for text in sentences:\n",
    "        surps, tokenized_sent = calculate_surprisal(text)\n",
    "        results = post_processing(tokenized_sent, surps, text)\n",
    "        for subject in subject_ids:\n",
    "            if len(df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'gpt2_surp'].tolist())==len(results):\n",
    "                df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'gpt2_surp']= results\n",
    "            elif len(df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'gpt2_surp'].tolist())!=0:\n",
    "                print('noo')\n",
    "                #df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'gpt2_surp']= results + results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "570e6923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264dde3",
   "metadata": {},
   "source": [
    "# Making the words smaller cases and punctuation less and Adding unique WordTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fa829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def process_word(row):\n",
    "    return row['Word'].rstrip(string.punctuation).lower()\n",
    "df['Word']=df.apply(process_word,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c4d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df['Sentence'].unique())\n",
    "id_dict = {sentences[i]:i for i in range(len(sentences))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3070790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return id_dict[row['Sentence']]\n",
    "df = df.drop(['Group'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b41e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group'] = df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce5b6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WordToken']=[None]*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8036b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_word(row):\n",
    "    #Adding the wordnum and sentence number after each token\n",
    "    return '{}_{}_{}'.format(row['Word'],row['Wordnum'],row['Group'])\n",
    "\n",
    "df['WordToken']=df.apply(change_word,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d93658",
   "metadata": {},
   "source": [
    "# Adding Length and Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "645d462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the columns of length and frequency\n",
    "import numpy as np\n",
    "freq = pd.read_csv(\"/om/user/snpushpi/pilot_results/subtlex.csv\")\n",
    "f = {row.Word : np.log(row.FREQcount) for index, row in freq.iterrows()}\n",
    "minfreq = min(f.values())\n",
    "def get_f(word):\n",
    "    word = re.sub('[\\.\\,\\:\\-\\?\\!\\)\\(\\\"]', \"\", word)\n",
    "    try:\n",
    "        fr = f[word]\n",
    "    except KeyError:\n",
    "        fr = minfreq\n",
    "    return fr\n",
    "def get_length(word):\n",
    "    word = re.sub('[\\.\\,\\:\\-\\?\\!\\)\\(\\\"]', \"\", word)\n",
    "    return len(word)\n",
    "import re\n",
    "\n",
    "df['Frequency'] = df['Word'].apply(lambda x: get_f(x))\n",
    "df['Length'] = df['Word'].apply(lambda x: get_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cc8b8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Controller</th>\n",
       "      <th>Item</th>\n",
       "      <th>Element</th>\n",
       "      <th>Type</th>\n",
       "      <th>Wordnum</th>\n",
       "      <th>Word</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Word On</th>\n",
       "      <th>...</th>\n",
       "      <th>First_RT</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>RT</th>\n",
       "      <th>Condition_ID</th>\n",
       "      <th>correctness</th>\n",
       "      <th>gpt2_surp</th>\n",
       "      <th>Group</th>\n",
       "      <th>WordToken</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>1</td>\n",
       "      <td>young</td>\n",
       "      <td>bills</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>636</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>636</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>11.910626</td>\n",
       "      <td>0</td>\n",
       "      <td>young_1_0</td>\n",
       "      <td>9.425613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>2</td>\n",
       "      <td>woman</td>\n",
       "      <td>goals</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>552</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>552</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>3.180175</td>\n",
       "      <td>0</td>\n",
       "      <td>woman_2_0</td>\n",
       "      <td>10.006315</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>3</td>\n",
       "      <td>sitting</td>\n",
       "      <td>revenue</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1090</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>1090</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>6.988459</td>\n",
       "      <td>0</td>\n",
       "      <td>sitting_3_0</td>\n",
       "      <td>8.479284</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>jack</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>663</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>663</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>2.411971</td>\n",
       "      <td>0</td>\n",
       "      <td>on_4_0</td>\n",
       "      <td>12.779146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>ago</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>577</td>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>577</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>1.629527</td>\n",
       "      <td>0</td>\n",
       "      <td>a_5_0</td>\n",
       "      <td>13.855864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33956</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>9</td>\n",
       "      <td>banana</td>\n",
       "      <td>portal</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>673</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>673</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>11.087739</td>\n",
       "      <td>97</td>\n",
       "      <td>banana_9_97</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33957</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>10</td>\n",
       "      <td>slices</td>\n",
       "      <td>devout</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>997</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>997</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>4.746374</td>\n",
       "      <td>97</td>\n",
       "      <td>slices_10_97</td>\n",
       "      <td>4.574711</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33958</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>11</td>\n",
       "      <td>atop</td>\n",
       "      <td>sane</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1080</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>1080</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>13.865226</td>\n",
       "      <td>97</td>\n",
       "      <td>atop_11_97</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33959</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>12</td>\n",
       "      <td>the</td>\n",
       "      <td>knew</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>494</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>494</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>3.505625</td>\n",
       "      <td>97</td>\n",
       "      <td>the_12_97</td>\n",
       "      <td>14.222247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33960</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>13</td>\n",
       "      <td>bread</td>\n",
       "      <td>fails.</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1048</td>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>1048</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>5.06699</td>\n",
       "      <td>97</td>\n",
       "      <td>bread_13_97</td>\n",
       "      <td>7.275865</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31261 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time_ID                        Subject_ID Controller  Item  Element  \\\n",
       "1      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "2      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "3      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "4      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "5      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "...           ...                               ...        ...   ...      ...   \n",
       "33956  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33957  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33958  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33959  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33960  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "\n",
       "           Type  Wordnum     Word      Alt  Word On  ... First_RT  \\\n",
       "1      group_01        1    young    bills        1  ...      636   \n",
       "2      group_01        2    woman    goals        1  ...      552   \n",
       "3      group_01        3  sitting  revenue        1  ...     1090   \n",
       "4      group_01        4       on     jack        0  ...      663   \n",
       "5      group_01        5        a      ago        1  ...      577   \n",
       "...         ...      ...      ...      ...      ...  ...      ...   \n",
       "33956  group_11        9   banana   portal        1  ...      673   \n",
       "33957  group_11       10   slices   devout        0  ...      997   \n",
       "33958  group_11       11     atop     sane        0  ...     1080   \n",
       "33959  group_11       12      the     knew        0  ...      494   \n",
       "33960  group_11       13    bread   fails.        0  ...     1048   \n",
       "\n",
       "                                                Sentence    RT Condition_ID  \\\n",
       "1      A young woman sitting on a curb next to a fire...   636           no   \n",
       "2      A young woman sitting on a curb next to a fire...   552           no   \n",
       "3      A young woman sitting on a curb next to a fire...  1090           no   \n",
       "4      A young woman sitting on a curb next to a fire...   663           no   \n",
       "5      A young woman sitting on a curb next to a fire...   577           no   \n",
       "...                                                  ...   ...          ...   \n",
       "33956  French bread on a plate with eggs, bacon and b...   673           no   \n",
       "33957  French bread on a plate with eggs, bacon and b...   997           no   \n",
       "33958  French bread on a plate with eggs, bacon and b...  1080           no   \n",
       "33959  French bread on a plate with eggs, bacon and b...   494           no   \n",
       "33960  French bread on a plate with eggs, bacon and b...  1048           no   \n",
       "\n",
       "      correctness  gpt2_surp Group     WordToken  Frequency  Length  \n",
       "1         correct  11.910626     0     young_1_0   9.425613       5  \n",
       "2         correct   3.180175     0     woman_2_0  10.006315       5  \n",
       "3         correct   6.988459     0   sitting_3_0   8.479284       7  \n",
       "4         correct   2.411971     0        on_4_0  12.779146       2  \n",
       "5         correct   1.629527     0         a_5_0  13.855864       1  \n",
       "...           ...        ...   ...           ...        ...     ...  \n",
       "33956     correct  11.087739    97   banana_9_97   6.304449       6  \n",
       "33957     correct   4.746374    97  slices_10_97   4.574711       6  \n",
       "33958     correct  13.865226    97    atop_11_97   3.951244       4  \n",
       "33959     correct   3.505625    97     the_12_97  14.222247       3  \n",
       "33960     correct    5.06699    97   bread_13_97   7.275865       5  \n",
       "\n",
       "[31261 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e1b7b",
   "metadata": {},
   "source": [
    "# Adding Image IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75c41d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_image_id(row):\n",
    "    first_ind = int(row['Type'][-2])\n",
    "    second_ind = int(row['Type'][-1])\n",
    "    dictionary = all_items[first_ind][second_ind]\n",
    "    if dictionary[row['Sentence']].startswith('w'):\n",
    "        return dictionary[row['Sentence']][2:]\n",
    "    elif dictionary[row['Sentence']].isdigit():\n",
    "        return None\n",
    "    else:\n",
    "        return dictionary[row['Sentence']]\n",
    "\n",
    "df['image_id']= df.apply(compute_image_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075946bb",
   "metadata": {},
   "source": [
    "# Adding BLIP2 Surprisal (If ever anyone to rerun make sure to allocate a lot of memory and a definitely a GPU for this task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b5da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "# from accelerate import Accelerator\n",
    "\n",
    "# accelerator = Accelerator()\n",
    "# device = accelerator.device\n",
    "# print(device)\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b4038c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:14<00:00,  7.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Blip2ForConditionalGeneration(\n",
       "  (vision_model): Blip2VisionModel(\n",
       "    (embeddings): Blip2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (encoder): Blip2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (12): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (13): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (14): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (15): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (16): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (17): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (18): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (19): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (20): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (21): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (22): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (23): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (24): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (25): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (26): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (27): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (28): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (29): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (30): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (31): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (32): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (33): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (34): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (35): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (36): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (37): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (38): Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (qformer): Blip2QFormerModel(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): Blip2QFormerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (language_projection): Linear(in_features=768, out_features=2560, bias=True)\n",
       "  (language_model): OPTForCausalLM(\n",
       "    (model): OPTModel(\n",
       "      (decoder): OPTDecoder(\n",
       "        (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
       "        (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
       "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (24): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (25): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (26): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (27): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (28): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (29): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (30): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (31): OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=50272, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\",torch_dtype=torch.float16)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "893ffae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "def calculate_surprisal(sentence, url):\n",
    "    image = Image.open(requests.get(url, stream=True).raw)\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device, torch.float16)\n",
    "    input_ids = processor.tokenizer(sentence, return_tensors = 'pt').input_ids.to(device)\n",
    "    output_logits = model(pixel_values, input_ids = input_ids, return_dict = True).logits.detach()\n",
    "    considered_logits = output_logits[:,32:,:]\n",
    "    result = [0]\n",
    "    #token_probs = output_logits\n",
    "    for i in range(1, input_ids.shape[1]-1):\n",
    "        token_logits = considered_logits[:,i,:]\n",
    "        token_prob = torch.log_softmax(token_logits,dim=-1)[0,input_ids[0,i+1]]\n",
    "        token_surprisal = -token_prob/math.log(2)\n",
    "        result.append(token_surprisal.item())\n",
    "        # print(tokenizer.convert_ids_to_tokens([encoded[0,i+1]]), token_surprisal)\n",
    "    return result, processor.tokenizer.tokenize(sentence)\n",
    "\n",
    "def post_processing(tokenized_sent, surps, sentence):\n",
    "    final_surp = []\n",
    "    counter = 0\n",
    "    assert len(tokenized_sent)==len(surps)\n",
    "    for (i,token) in enumerate(tokenized_sent):\n",
    "        if not token.startswith('Ġ'):\n",
    "            counter+=surps[i]\n",
    "        else:\n",
    "            final_surp.append(counter)\n",
    "            counter = surps[i]\n",
    "        if i==len(tokenized_sent)-1:\n",
    "            final_surp.append(counter)\n",
    "#     if len(final_surp)!= len(sentence.split(' ')):\n",
    "#         print(tokenized_sent,sentence,len(final_surp),sentence.split(' '))\n",
    "    assert len(final_surp)== len(sentence.split(' '))\n",
    "    return final_surp[1:]\n",
    "    \n",
    "def run():\n",
    "    for text in sentences:\n",
    "        mod_text = text.replace('%2C',',')\n",
    "        for subject in subject_ids:\n",
    "            l = df.loc[(df['Sentence']==text) & (df['Subject_ID']==subject), 'image_id'].unique()\n",
    "            assert len(l)==1 or len(l)==0\n",
    "            if len(l)==1:\n",
    "                image_id = df.loc[(df['Sentence']==text) & (df['Subject_ID']==subject), 'image_id'].unique()[0]\n",
    "                if image_id is not None:\n",
    "                    url = 'http://images.cocodataset.org/val2017/' + str(image_id)\n",
    "                    print(url)\n",
    "                    surps, tokenized_sent = calculate_surprisal(mod_text,url)\n",
    "                    results = post_processing(tokenized_sent, surps, mod_text)\n",
    "                    #print(len(df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'gpt2_surp'].tolist()),len(results))\n",
    "                    if len(df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'blip2_surp'].tolist())!=0:\n",
    "                        df.loc[(df['Sentence']==text) & (df['Subject_ID'] == subject), 'blip2_surp']= results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe7a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['blip2_surp'] = [None]*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66025e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sentences = df['Sentence'].unique()\n",
    "subject_ids = df['Subject_ID'].unique()\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965ab45",
   "metadata": {},
   "source": [
    "# Adding Groundedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e36c28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"final_grounding_data.zip\", 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d42cf67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 65 CSV files into combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder where your CSV files are located\n",
    "folder_path = 'final_grounding_data/'\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Check if the file is empty (has a file size of 0 bytes)\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Append the data to the combined_data DataFrame\n",
    "            combined_data = combined_data.append(data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_data.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "print(f\"Combined {len(os.listdir(folder_path))} CSV files into combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b159980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_str_to_list(str_repr):\n",
    "    return ast.literal_eval(str_repr)\n",
    "\n",
    "combined_data['response'] = combined_data['response'].apply(convert_str_to_list)\n",
    "\n",
    "def convert_to_int(num_str_list):\n",
    "    return [int(num_str) for num_str in num_str_list]\n",
    "\n",
    "# Apply the conversion function to the 'numbers_column' using map\n",
    "combined_data['response'] = combined_data['response'].map(convert_to_int)\n",
    "#convert_to_int([\"10\",\"10\",\"10\",\"10\",\"10\",\"10\",\"10\",\"10\",\"10\",\"10\",\"10\",\"10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f6b06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by column A and calculate the elementwise average\n",
    "grouped = combined_data.groupby('stimulus')['response'].apply(lambda x: [sum(i) / len(i) for i in zip(*x)])\n",
    "\n",
    "# Create a new DataFrame with the calculated averages\n",
    "result_df = pd.DataFrame(grouped).reset_index()\n",
    "result_df.columns = ['stimulus', 'response_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27ba85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_response = {}\n",
    "stims = result_df['stimulus'].unique()\n",
    "for stim in stims:\n",
    "    val = result_df[result_df['stimulus']==stim]\n",
    "    stim_response[stim] = val['response_avg'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f89d88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = list(result_df.loc[result_df['stimulus']=='A sign mounted to a pole that reads \" No Stops \".','response_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68f7e4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.142857142857143,\n",
       "  9.428571428571429,\n",
       "  8.0,\n",
       "  3.2857142857142856,\n",
       "  3.2857142857142856,\n",
       "  9.285714285714286,\n",
       "  2.142857142857143,\n",
       "  3.7142857142857144,\n",
       "  -4.714285714285714,\n",
       "  9.142857142857142,\n",
       "  9.142857142857142,\n",
       "  -5.714285714285714]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_list #notice how we collected groundedness for \" signs, which we would strip off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34ad5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_good_list = good_list[0][0:8]+good_list[0][9:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad6272da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sign mounted to a pole that reads \" No Stops \". cry\n",
      "A sign mounted to a pole that reads No Stops. cry\n"
     ]
    }
   ],
   "source": [
    "for sent in stim_response:\n",
    "    if sent not in sentences:\n",
    "        print(sent,'cry')\n",
    "\n",
    "for sent in sentences:\n",
    "    if sent not in stim_response:\n",
    "        print(sent,'cry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61940250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the stim response key\n",
    "stim_response['A sign mounted to a pole that reads No Stops.'] = final_good_list\n",
    "del stim_response['A sign mounted to a pole that reads \" No Stops \".']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8c11b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['groundedness']=[None]*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b914d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df['Subject_ID'].unique()\n",
    "for sentence in stim_response:\n",
    "    for subject in subjects:\n",
    "        #print(len(stim_response[sentence][1:]),len(list(final_data_df.loc[(final_data_df['Sentence']==sentence) & (final_data_df['Subject_ID']==subject),'groundedness'])))\n",
    "        if len(list(df.loc[(df['Sentence']==sentence) & (df['Subject_ID']==subject),'groundedness']))!=0:\n",
    "            #print(len(list(combined_data.loc[combined_data['Sentence']==sentence,'groundedness'][1:])))\n",
    "            #print(len(final_data_df.loc[final_data_df['Sentence']==sentence,'groundedness']))\n",
    "            df.loc[(df['Sentence']==sentence) & (df['Subject_ID']==subject),'groundedness']= stim_response[sentence][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa23b5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Controller</th>\n",
       "      <th>Item</th>\n",
       "      <th>Element</th>\n",
       "      <th>Type</th>\n",
       "      <th>Wordnum</th>\n",
       "      <th>Word</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Word On</th>\n",
       "      <th>...</th>\n",
       "      <th>Condition_ID</th>\n",
       "      <th>correctness</th>\n",
       "      <th>gpt2_surp</th>\n",
       "      <th>Group</th>\n",
       "      <th>WordToken</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Length</th>\n",
       "      <th>image_id</th>\n",
       "      <th>blip2_surp</th>\n",
       "      <th>groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>1</td>\n",
       "      <td>young</td>\n",
       "      <td>bills</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>11.910626</td>\n",
       "      <td>0</td>\n",
       "      <td>young_1_0</td>\n",
       "      <td>9.425613</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>2</td>\n",
       "      <td>woman</td>\n",
       "      <td>goals</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>3.180175</td>\n",
       "      <td>0</td>\n",
       "      <td>woman_2_0</td>\n",
       "      <td>10.006315</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>3</td>\n",
       "      <td>sitting</td>\n",
       "      <td>revenue</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>6.988459</td>\n",
       "      <td>0</td>\n",
       "      <td>sitting_3_0</td>\n",
       "      <td>8.479284</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>jack</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>2.411971</td>\n",
       "      <td>0</td>\n",
       "      <td>on_4_0</td>\n",
       "      <td>12.779146</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>ago</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>1.629527</td>\n",
       "      <td>0</td>\n",
       "      <td>a_5_0</td>\n",
       "      <td>13.855864</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33956</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>9</td>\n",
       "      <td>banana</td>\n",
       "      <td>portal</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>11.087739</td>\n",
       "      <td>97</td>\n",
       "      <td>banana_9_97</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33957</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>10</td>\n",
       "      <td>slices</td>\n",
       "      <td>devout</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>4.746374</td>\n",
       "      <td>97</td>\n",
       "      <td>slices_10_97</td>\n",
       "      <td>4.574711</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33958</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>11</td>\n",
       "      <td>atop</td>\n",
       "      <td>sane</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>13.865226</td>\n",
       "      <td>97</td>\n",
       "      <td>atop_11_97</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33959</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>12</td>\n",
       "      <td>the</td>\n",
       "      <td>knew</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>3.505625</td>\n",
       "      <td>97</td>\n",
       "      <td>the_12_97</td>\n",
       "      <td>14.222247</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33960</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>13</td>\n",
       "      <td>bread</td>\n",
       "      <td>fails.</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>correct</td>\n",
       "      <td>5.06699</td>\n",
       "      <td>97</td>\n",
       "      <td>bread_13_97</td>\n",
       "      <td>7.275865</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31261 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time_ID                        Subject_ID Controller  Item  Element  \\\n",
       "1      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "2      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "3      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "4      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "5      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "...           ...                               ...        ...   ...      ...   \n",
       "33956  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33957  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33958  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33959  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "33960  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "\n",
       "           Type  Wordnum     Word      Alt  Word On  ... Condition_ID  \\\n",
       "1      group_01        1    young    bills        1  ...           no   \n",
       "2      group_01        2    woman    goals        1  ...           no   \n",
       "3      group_01        3  sitting  revenue        1  ...           no   \n",
       "4      group_01        4       on     jack        0  ...           no   \n",
       "5      group_01        5        a      ago        1  ...           no   \n",
       "...         ...      ...      ...      ...      ...  ...          ...   \n",
       "33956  group_11        9   banana   portal        1  ...           no   \n",
       "33957  group_11       10   slices   devout        0  ...           no   \n",
       "33958  group_11       11     atop     sane        0  ...           no   \n",
       "33959  group_11       12      the     knew        0  ...           no   \n",
       "33960  group_11       13    bread   fails.        0  ...           no   \n",
       "\n",
       "      correctness  gpt2_surp Group     WordToken  Frequency Length  image_id  \\\n",
       "1         correct  11.910626     0     young_1_0   9.425613      5      None   \n",
       "2         correct   3.180175     0     woman_2_0  10.006315      5      None   \n",
       "3         correct   6.988459     0   sitting_3_0   8.479284      7      None   \n",
       "4         correct   2.411971     0        on_4_0  12.779146      2      None   \n",
       "5         correct   1.629527     0         a_5_0  13.855864      1      None   \n",
       "...           ...        ...   ...           ...        ...    ...       ...   \n",
       "33956     correct  11.087739    97   banana_9_97   6.304449      6      None   \n",
       "33957     correct   4.746374    97  slices_10_97   4.574711      6      None   \n",
       "33958     correct  13.865226    97    atop_11_97   3.951244      4      None   \n",
       "33959     correct   3.505625    97     the_12_97  14.222247      3      None   \n",
       "33960     correct    5.06699    97   bread_13_97   7.275865      5      None   \n",
       "\n",
       "      blip2_surp  groundedness  \n",
       "1           None           2.5  \n",
       "2           None           9.0  \n",
       "3           None          9.75  \n",
       "4           None           3.0  \n",
       "5           None         0.875  \n",
       "...          ...           ...  \n",
       "33956       None         9.625  \n",
       "33957       None          8.25  \n",
       "33958       None         5.625  \n",
       "33959       None         0.125  \n",
       "33960       None         8.125  \n",
       "\n",
       "[31261 rows x 24 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f7332",
   "metadata": {},
   "source": [
    "# Adding POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e96a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_v2_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7225434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from click->nltk) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /mindhive/nklab5/users/snpushpi/packages/anaconda3/envs/cat/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.14.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3910215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "# Set the path to the Stanford POS Tagger jar and model\n",
    "stanford_pos_jar = 'stanford-postagger-4.2.0.jar'\n",
    "stanford_pos_model = 'english-bidirectional-distsim.tagger'\n",
    "stanford_pos_tagger = StanfordPOSTagger(stanford_pos_model, stanford_pos_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffa27ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/snpushpi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d1c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def open_closed_classify(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = stanford_pos_tagger.tag(tokens)\n",
    "\n",
    "    # Define open class POS tags based on the Stanford tagset\n",
    "    open_class_tags = {'NN', 'NNS','NNP','NNPS','VB', 'VBD', 'VBG', 'VBN', 'VBP','VBZ','JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS'}\n",
    "\n",
    "    #Other than auxiliary verbs and quantifiers, we also have classified very light semantic words as closed class words. Besides, verbs like 'makes'\n",
    "    # and 'return' that in those specific sentences are also not grounded at all are considered as closed class words\n",
    "    auxuliary_verbs_quantifiers = {'has','have','had','does','do','did','be','am','is','are','was','were','being','been',\n",
    "                    'can', 'could', 'will', 'would', 'shall', 'should', 'may', 'might', 'must', 'having','other','front','mostly','empty','only'\n",
    "                    ,'few','lot','half','as','well','more','on','half','next','several','various','types','filled','multiple',\n",
    "                                   'available','makes','including','return','variety','middle'}\n",
    "    # Classify each POS tag as open or closed class\n",
    "    classified_tags = [(word, 'Open' if tag in open_class_tags and word not in auxuliary_verbs_quantifiers else 'Closed') for word, tag in pos_tags]\n",
    "    final_tags = []\n",
    "    for word,tag in classified_tags:\n",
    "        if word not in string.punctuation:\n",
    "            final_tags.append(tag)\n",
    "    return final_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2e443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POS']=[None]*len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b893f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['Sentence'].unique().tolist()\n",
    "subjects = df['Subject_ID'].unique().tolist()\n",
    "for sentence in sentences:\n",
    "    tags = open_closed_classify(sentence.replace('%2C',','))\n",
    "    for subject in subjects:\n",
    "        #print(df.loc[(df['Sentence']==sentence) & (df['Subject_ID']==subject),'POS'].tolist())\n",
    "        if len(df.loc[(df['Sentence']==sentence) & (df['Subject_ID']==subject),'POS'].tolist())!=0:\n",
    "            df.loc[(df['Sentence']==sentence) & (df['Subject_ID']==subject),'POS']= tags[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86098c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Controller</th>\n",
       "      <th>Item</th>\n",
       "      <th>Element</th>\n",
       "      <th>Type</th>\n",
       "      <th>Wordnum</th>\n",
       "      <th>Word</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Word On</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness</th>\n",
       "      <th>gpt2_surp</th>\n",
       "      <th>Group</th>\n",
       "      <th>WordToken</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Length</th>\n",
       "      <th>image_id</th>\n",
       "      <th>blip2_surp</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>1</td>\n",
       "      <td>young</td>\n",
       "      <td>bills</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>11.910626</td>\n",
       "      <td>0</td>\n",
       "      <td>young_1_0</td>\n",
       "      <td>9.425613</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>2</td>\n",
       "      <td>woman</td>\n",
       "      <td>goals</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>3.180175</td>\n",
       "      <td>0</td>\n",
       "      <td>woman_2_0</td>\n",
       "      <td>10.006315</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>3</td>\n",
       "      <td>sitting</td>\n",
       "      <td>revenue</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>6.988459</td>\n",
       "      <td>0</td>\n",
       "      <td>sitting_3_0</td>\n",
       "      <td>8.479284</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.750</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>jack</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>2.411971</td>\n",
       "      <td>0</td>\n",
       "      <td>on_4_0</td>\n",
       "      <td>12.779146</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1700421960</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_01</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>ago</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>1.629527</td>\n",
       "      <td>0</td>\n",
       "      <td>a_5_0</td>\n",
       "      <td>13.855864</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31256</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>9</td>\n",
       "      <td>banana</td>\n",
       "      <td>portal</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>11.087739</td>\n",
       "      <td>97</td>\n",
       "      <td>banana_9_97</td>\n",
       "      <td>6.304449</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.625</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31257</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>10</td>\n",
       "      <td>slices</td>\n",
       "      <td>devout</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>4.746374</td>\n",
       "      <td>97</td>\n",
       "      <td>slices_10_97</td>\n",
       "      <td>4.574711</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.250</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31258</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>11</td>\n",
       "      <td>atop</td>\n",
       "      <td>sane</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>13.865226</td>\n",
       "      <td>97</td>\n",
       "      <td>atop_11_97</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.625</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31259</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>12</td>\n",
       "      <td>the</td>\n",
       "      <td>knew</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>3.505625</td>\n",
       "      <td>97</td>\n",
       "      <td>the_12_97</td>\n",
       "      <td>14.222247</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31260</th>\n",
       "      <td>1700426388</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>Maze</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>group_11</td>\n",
       "      <td>13</td>\n",
       "      <td>bread</td>\n",
       "      <td>fails.</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>correct</td>\n",
       "      <td>5.066990</td>\n",
       "      <td>97</td>\n",
       "      <td>bread_13_97</td>\n",
       "      <td>7.275865</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.125</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31261 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time_ID                        Subject_ID Controller  Item  Element  \\\n",
       "0      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "1      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "2      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "3      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "4      1700421960  2f19f9ae48a67f4e2b28506beb1da0d1       Maze    48        1   \n",
       "...           ...                               ...        ...   ...      ...   \n",
       "31256  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "31257  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "31258  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "31259  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "31260  1700426388  98364205838e7b79b626fe09aeccf97c       Maze    48        1   \n",
       "\n",
       "           Type  Wordnum     Word      Alt  Word On  ... correctness  \\\n",
       "0      group_01        1    young    bills        1  ...     correct   \n",
       "1      group_01        2    woman    goals        1  ...     correct   \n",
       "2      group_01        3  sitting  revenue        1  ...     correct   \n",
       "3      group_01        4       on     jack        0  ...     correct   \n",
       "4      group_01        5        a      ago        1  ...     correct   \n",
       "...         ...      ...      ...      ...      ...  ...         ...   \n",
       "31256  group_11        9   banana   portal        1  ...     correct   \n",
       "31257  group_11       10   slices   devout        0  ...     correct   \n",
       "31258  group_11       11     atop     sane        0  ...     correct   \n",
       "31259  group_11       12      the     knew        0  ...     correct   \n",
       "31260  group_11       13    bread   fails.        0  ...     correct   \n",
       "\n",
       "       gpt2_surp Group     WordToken  Frequency Length  image_id  blip2_surp  \\\n",
       "0      11.910626     0     young_1_0   9.425613      5       NaN         NaN   \n",
       "1       3.180175     0     woman_2_0  10.006315      5       NaN         NaN   \n",
       "2       6.988459     0   sitting_3_0   8.479284      7       NaN         NaN   \n",
       "3       2.411971     0        on_4_0  12.779146      2       NaN         NaN   \n",
       "4       1.629527     0         a_5_0  13.855864      1       NaN         NaN   \n",
       "...          ...   ...           ...        ...    ...       ...         ...   \n",
       "31256  11.087739    97   banana_9_97   6.304449      6       NaN         NaN   \n",
       "31257   4.746374    97  slices_10_97   4.574711      6       NaN         NaN   \n",
       "31258  13.865226    97    atop_11_97   3.951244      4       NaN         NaN   \n",
       "31259   3.505625    97     the_12_97  14.222247      3       NaN         NaN   \n",
       "31260   5.066990    97   bread_13_97   7.275865      5       NaN         NaN   \n",
       "\n",
       "      groundedness     POS  \n",
       "0            2.500    Open  \n",
       "1            9.000    Open  \n",
       "2            9.750    Open  \n",
       "3            3.000  Closed  \n",
       "4            0.875  Closed  \n",
       "...            ...     ...  \n",
       "31256        9.625    Open  \n",
       "31257        8.250    Open  \n",
       "31258        5.625  Closed  \n",
       "31259        0.125  Closed  \n",
       "31260        8.125    Open  \n",
       "\n",
       "[31261 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a9b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_v2_all_with_error_info.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd968a",
   "metadata": {},
   "source": [
    "# This part below is for generating a dataset with sentence level error information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "652d9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with unique combinations of 'sentence', 'subject_id', and 'condition_id'\n",
    "new_df = df[['Sentence', 'Subject_ID', 'Condition_ID']].drop_duplicates()\n",
    "new_df['correctness']=[1]*len(new_df)\n",
    "# # Check if any 'RT' value is None for each group in the original DataFrame\n",
    "# missing_rt_mask = df.groupby(['Sentence', 'Subject_ID', 'Condition_ID'])['RT'].apply(lambda x: x.isna().any()).reset_index()\n",
    "\n",
    "# # Merge the new DataFrame with the missing_rt_mask\n",
    "# new_df = pd.merge(new_df, missing_rt_mask, on=['Sentence', 'Subject_ID', 'Condition_ID'], how='left')\n",
    "\n",
    "# # Fill NaN values with False (no missing RT)\n",
    "# new_df['Correctness'] = new_df['RT'].fillna(False).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "359e5bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Condition_ID</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Two giraffes standing on a dirt expanse with t...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A girl in an orange sweater is sitting on a sk...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The bench is in a shady area surrounded by pla...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>An old man sitting on a bench in a public park.</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33886</th>\n",
       "      <td>A stop sign installed upside down on a street ...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33896</th>\n",
       "      <td>A calculator and cell phone lay on a desk in f...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>A dark colored cat that is looking up at a tel...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>wrong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33931</th>\n",
       "      <td>An airplane flies high above in the sky with t...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33947</th>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  \\\n",
       "0      A young woman sitting on a curb next to a fire...   \n",
       "16     Two giraffes standing on a dirt expanse with t...   \n",
       "27     A girl in an orange sweater is sitting on a sk...   \n",
       "38     The bench is in a shady area surrounded by pla...   \n",
       "48       An old man sitting on a bench in a public park.   \n",
       "...                                                  ...   \n",
       "33886  A stop sign installed upside down on a street ...   \n",
       "33896  A calculator and cell phone lay on a desk in f...   \n",
       "33910  A dark colored cat that is looking up at a tel...   \n",
       "33931  An airplane flies high above in the sky with t...   \n",
       "33947  French bread on a plate with eggs, bacon and b...   \n",
       "\n",
       "                             Subject_ID Condition_ID  correctness  \n",
       "0      2f19f9ae48a67f4e2b28506beb1da0d1           no            1  \n",
       "16     2f19f9ae48a67f4e2b28506beb1da0d1           no            1  \n",
       "27     2f19f9ae48a67f4e2b28506beb1da0d1      correct            1  \n",
       "38     2f19f9ae48a67f4e2b28506beb1da0d1      correct            1  \n",
       "48     2f19f9ae48a67f4e2b28506beb1da0d1           no            1  \n",
       "...                                 ...          ...          ...  \n",
       "33886  98364205838e7b79b626fe09aeccf97c      correct            1  \n",
       "33896  98364205838e7b79b626fe09aeccf97c      correct            1  \n",
       "33910  98364205838e7b79b626fe09aeccf97c        wrong            1  \n",
       "33931  98364205838e7b79b626fe09aeccf97c           no            1  \n",
       "33947  98364205838e7b79b626fe09aeccf97c           no            1  \n",
       "\n",
       "[2700 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a519a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
   ]
    }
   ],
   "source": [
    "sentences = df['Sentence'].unique()\n",
    "subject_ids = df['Subject_ID'].unique()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for subject in subject_ids:\n",
    "        if any((df['Subject_ID'] == subject) & (df['Sentence'] == sentence) & (df['RT']==\"None\")):\n",
    "            print('pip')\n",
    "            # Delete all rows where column A and column B have the specific values\n",
    "            new_df.loc[(new_df['Sentence']==sentence) & (new_df['Subject_ID']==subject),'correctness']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e20b8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Condition_ID</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young woman sitting on a curb next to a fire...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Two giraffes standing on a dirt expanse with t...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A girl in an orange sweater is sitting on a sk...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The bench is in a shady area surrounded by pla...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>An old man sitting on a bench in a public park.</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33886</th>\n",
       "      <td>A stop sign installed upside down on a street ...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33896</th>\n",
       "      <td>A calculator and cell phone lay on a desk in f...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>A dark colored cat that is looking up at a tel...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>wrong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33931</th>\n",
       "      <td>An airplane flies high above in the sky with t...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33947</th>\n",
       "      <td>French bread on a plate with eggs, bacon and b...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  \\\n",
       "0      A young woman sitting on a curb next to a fire...   \n",
       "16     Two giraffes standing on a dirt expanse with t...   \n",
       "27     A girl in an orange sweater is sitting on a sk...   \n",
       "38     The bench is in a shady area surrounded by pla...   \n",
       "48       An old man sitting on a bench in a public park.   \n",
       "...                                                  ...   \n",
       "33886  A stop sign installed upside down on a street ...   \n",
       "33896  A calculator and cell phone lay on a desk in f...   \n",
       "33910  A dark colored cat that is looking up at a tel...   \n",
       "33931  An airplane flies high above in the sky with t...   \n",
       "33947  French bread on a plate with eggs, bacon and b...   \n",
       "\n",
       "                             Subject_ID Condition_ID  correctness  \n",
       "0      2f19f9ae48a67f4e2b28506beb1da0d1           no            1  \n",
       "16     2f19f9ae48a67f4e2b28506beb1da0d1           no            1  \n",
       "27     2f19f9ae48a67f4e2b28506beb1da0d1      correct            1  \n",
       "38     2f19f9ae48a67f4e2b28506beb1da0d1      correct            1  \n",
       "48     2f19f9ae48a67f4e2b28506beb1da0d1           no            1  \n",
       "...                                 ...          ...          ...  \n",
       "33886  98364205838e7b79b626fe09aeccf97c      correct            1  \n",
       "33896  98364205838e7b79b626fe09aeccf97c      correct            1  \n",
       "33910  98364205838e7b79b626fe09aeccf97c        wrong            1  \n",
       "33931  98364205838e7b79b626fe09aeccf97c           no            1  \n",
       "33947  98364205838e7b79b626fe09aeccf97c           no            1  \n",
       "\n",
       "[2700 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed542e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Condition_ID</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>A tennis player makes a quick shuffle to retur...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>A tray topped with a chicken sandwich next to ...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Two men are posing for a photo, one man is hol...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Several containers of food and beverages on a ...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>A cat sitting on the hood of a parked black ca...</td>\n",
       "      <td>2f19f9ae48a67f4e2b28506beb1da0d1</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33491</th>\n",
       "      <td>A man sitting on the ground, fixing a motorcyc...</td>\n",
       "      <td>8ec181c1f3a657b480366f4261961dcb</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33570</th>\n",
       "      <td>A white cake covered in flowers and white fros...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33677</th>\n",
       "      <td>A clock between two bronze flamingo statues on...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33725</th>\n",
       "      <td>A close-up photo of a man as he holds a piece ...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33843</th>\n",
       "      <td>Multiple aircraft suspended from the ceiling o...</td>\n",
       "      <td>98364205838e7b79b626fe09aeccf97c</td>\n",
       "      <td>wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  \\\n",
       "219    A tennis player makes a quick shuffle to retur...   \n",
       "298    A tray topped with a chicken sandwich next to ...   \n",
       "311    Two men are posing for a photo, one man is hol...   \n",
       "339    Several containers of food and beverages on a ...   \n",
       "435    A cat sitting on the hood of a parked black ca...   \n",
       "...                                                  ...   \n",
       "33491  A man sitting on the ground, fixing a motorcyc...   \n",
       "33570  A white cake covered in flowers and white fros...   \n",
       "33677  A clock between two bronze flamingo statues on...   \n",
       "33725  A close-up photo of a man as he holds a piece ...   \n",
       "33843  Multiple aircraft suspended from the ceiling o...   \n",
       "\n",
       "                             Subject_ID Condition_ID  correctness  \n",
       "219    2f19f9ae48a67f4e2b28506beb1da0d1           no            0  \n",
       "298    2f19f9ae48a67f4e2b28506beb1da0d1        wrong            0  \n",
       "311    2f19f9ae48a67f4e2b28506beb1da0d1           no            0  \n",
       "339    2f19f9ae48a67f4e2b28506beb1da0d1        wrong            0  \n",
       "435    2f19f9ae48a67f4e2b28506beb1da0d1           no            0  \n",
       "...                                 ...          ...          ...  \n",
       "33491  8ec181c1f3a657b480366f4261961dcb      correct            0  \n",
       "33570  98364205838e7b79b626fe09aeccf97c           no            0  \n",
       "33677  98364205838e7b79b626fe09aeccf97c        wrong            0  \n",
       "33725  98364205838e7b79b626fe09aeccf97c      correct            0  \n",
       "33843  98364205838e7b79b626fe09aeccf97c        wrong            0  \n",
       "\n",
       "[338 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['correctness']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f03461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('error_ind.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35ff50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
